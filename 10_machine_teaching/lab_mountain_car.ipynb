{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-GBod1nv65dN"
   },
   "source": [
    "## Lab: Machine Teaching in the Mountain Car Environment\n",
    "\n",
    "### University of Virginia\n",
    "### Reinforcement Learning\n",
    "#### Last updated: April 11, 2025\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "krpOsEbE_aTj",
    "tags": []
   },
   "source": [
    "### Goal and Environment\n",
    "\n",
    "The mountain car problem:\n",
    "\n",
    "\"A car is on a one-dimensional track, positioned between two “mountains”. The goal is to drive up the mountain on the right; however, the car’s engine is not strong enough to scale the mountain in a single pass. Therefore, the only way to succeed is to drive back and forth to build up momentum.\"\n",
    "\n",
    "In the default environment, there is a reward of -1 per time step.  \n",
    "This is intended to prompt the car to reach the goal quickly.  \n",
    "Without additional reward signals, this is not an easy problem to solve.\n",
    "\n",
    "The episode terminates after 200 steps.\n",
    "\n",
    "This is the `gymnasium` environment that we want: `'MountainCar-v0'`\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./mtn_car.png\">\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Assignment\n",
    "\n",
    "1) Using the `'MountainCar-v0'` environment, show the state space and the action space. Explain what they mean.\n",
    "2) Have the agent take three steps and print the rewards  \n",
    "3) Attempt to run the agent for 250 steps. Print results that verify the episode is done after 200 steps.  \n",
    "4) Apply machine teaching and an RL algorithm to improve agent performance. Show all code and results below.\n",
    "\n",
    "**NOTE:** You might use the code/ideas from the Enes text (Chapter 10 starting on page 320). Note that this code will be dated as the `RLlib` codebase changes rapidly.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
