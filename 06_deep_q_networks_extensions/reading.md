## Reading

---

For First Module:  

1. [Prioritized Experience Replay](https://arxiv.org/abs/1511.05952). Pages 1-8 through discussion.   
A technique for assigning greater weight to observations that are more valuable for model improvement

2. [Deep Reinforcement Learning with Double Q-learning](https://arxiv.org/abs/1509.06461)  
Refinement to the deep Q-network to mitigate overestimates of action values

3. Revisit: Sutton and Barto Section 6.7: Maximization Bias and Double Learning  
Speaks to the bias from the double Q-learning paper and proposes an algorithm for tabular learning

---

For Second Module:  

4. [Dueling Network Architectures for Deep Reinforcement Learning
](https://arxiv.org/abs/1511.06581)  
A new neural network architecture for model-free RL

5. [Deep Reinforcement Learning for Sepsis Treatment](https://arxiv.org/pdf/1711.09602.pdf)

6. [Asynchronous Methods for Deep Reinforcement Learning](https://arxiv.org/abs/1602.01783)