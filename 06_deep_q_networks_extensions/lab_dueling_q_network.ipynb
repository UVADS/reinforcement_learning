{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2ba6549-8b15-4f95-9615-549dd5fa2f7c",
   "metadata": {},
   "source": [
    "### Lab: Navigating the Lunar Lander with a Dueling Deep Q Network\n",
    "\n",
    "### University of Virginia\n",
    "### Reinforcement Learning\n",
    "#### Last updated: February 27, 2024\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afeab41-bd5f-40e8-ad2f-e8999f13ed45",
   "metadata": {},
   "source": [
    "#### Instructions:\n",
    "\n",
    "You will work with the `LunarLander-v2` environment from `gymnasium` in this lab.  \n",
    "\n",
    "An overview of the environment can be found [here](https://gymnasium.farama.org/).  \n",
    "If you're curious about the source code, see [here](https://github.com/Farama-Foundation/Gymnasium/blob/main/gymnasium/envs/box2d/lunar_lander.py).\n",
    "\n",
    "Your mission will be to implement a dueling deep Q -network using PyTorch.  \n",
    "You might run this on Colab.\n",
    "\n",
    "There are a few specific tasks outlined below for you to solve.\n",
    "\n",
    "The bigger tasks will be to:\n",
    "\n",
    "- Show that the algorithm works to train the agent in the environment\n",
    "- Run episodes and show the results\n",
    "\n",
    "**Submission**  \n",
    "As you will likely have several files including this notebook, you can zip all files and submit.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285f77b4-736e-4287-a570-2ecb5158e1b5",
   "metadata": {},
   "source": [
    "![lunar](./lunar_lander1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c322b08-1720-43e0-a3b0-0788fc33b6a7",
   "metadata": {},
   "source": [
    "#### TOTAL POINTS: 12\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaec7e91-2f9e-4bae-8605-6a7f0d46e8a9",
   "metadata": {},
   "source": [
    "**Hint:** Modules you may need to install include:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e46143-14c0-45da-8268-2a4c7295ca0c",
   "metadata": {},
   "source": [
    "swig  \n",
    "gym[box2d]  \n",
    "gymnasium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53817399-20ed-42eb-ae9e-9b76369de8eb",
   "metadata": {},
   "source": [
    "#### 1) What is the penalty for crashing?  \n",
    "**(POINTS: 1)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0599cdf7-e5b8-4d62-8ac1-bd507f10084a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a304cd5-72e7-4f53-95d4-1cb9fcfb1d1f",
   "metadata": {},
   "source": [
    "#### 2) Set up the environment and run 2 steps by taking random actions.\n",
    "**(POINTS: 1)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e536f8-9cc1-4295-8283-3d9528ffb8f1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6704924-c33d-4135-bd79-7ffef75e7aa9",
   "metadata": {},
   "source": [
    "#### 3) Briefly discuss your approach to solving the problem  \n",
    "**(POINTS: 2)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b3cf8c-f121-46f0-a085-375f97a37398",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "894d315f-ed95-4b9a-b6f5-53e1305d272a",
   "metadata": {},
   "source": [
    "#### 4) Create supporting code files (`.py` format) to create the agent, train, and run episodes\n",
    "**(POINTS: 6)**\n",
    "\n",
    "Your code should include:\n",
    "\n",
    "- **(POINTS: 1)** A class for the dueling DQN agent \n",
    "- **(POINTS: 1)** An architecture with separate Value and Advantage streams\n",
    "- **(POINTS: 1)** A method called `forward()` for the forward pass of the algorithm\n",
    "- **(POINTS: 1)** A replay buffer\n",
    "- **(POINTS: 1)** A training function\n",
    "- **(POINTS: 1)** A function to run episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3039df88-158c-455d-9333-4a8fcd7d7ad2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7259568c-0352-4271-94cf-28361e1cabec",
   "metadata": {},
   "source": [
    "#### 5) Run the training and show evidence that the agent is learning.  \n",
    "\n",
    "For example, its average reward (score) should increase with more episodes.\n",
    "\n",
    "**(POINTS: 1 if successful)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3a90f5-4fe6-41fc-88a0-1d234672b3a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94d60b6e-3530-48d5-b1d0-7f837b5a8c1c",
   "metadata": {},
   "source": [
    "#### 6) Run a few episodes and show results\n",
    "**(POINTS: 1 if successful)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa3fffd-f96d-4773-a7bc-862cbf5eb310",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
