{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f16df62-ddac-4952-b637-b5dfd5f05a5b",
   "metadata": {},
   "source": [
    "### Approaches to Solving MDPs I: Dynamic Programming\n",
    "### Exercises: Robot Problem\n",
    "\n",
    "### University of Virginia\n",
    "### Reinforcement Learning\n",
    "#### Last updated: January 26, 2024\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45c194c-aaff-4b28-bf08-17f7c0a438b2",
   "metadata": {},
   "source": [
    "Based on the robot task to maximize reward on the tree below, answer the following questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30753a6-61b6-4b6f-94fc-db7a05a10019",
   "metadata": {},
   "source": [
    "![tree_task1](./tree_task1_binary.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad2a3f7-2ddd-47ad-8bd0-2a96ba8ae862",
   "metadata": {},
   "source": [
    "1) Background question: The dynamic programming approach is much more efficient than brute force search. Why is this the case?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5f12b5-5962-48d4-99fd-eb48d1c75a58",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bef50bba-2cb2-4652-8d2f-1627ccddd03a",
   "metadata": {},
   "source": [
    "2. Write an algorithm that will apply the data and compute the maximum value for the robot problem.  Print the results to verify it works properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdbf20c-5b75-4ef3-9c22-1742aebec422",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
