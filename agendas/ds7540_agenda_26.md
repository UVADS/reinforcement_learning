## DS 7540 Machine Learning IV - Reinforcement Learning: Agenda 26
  
---

### Upcoming Deliverables

- RLHF Quiz: Due Friday, Apr 25, 2025 by 11:59 PM 
- Journals 1-11. Due Friday, Apr 25, 2025, 11:59 PM

---

### Content

1. Review RLHF slides based on the blogs and papers below:

[Learning from Human Preferences](https://openai.com/research/learning-from-human-preferences)

[Deep Reinforcement Learning from Human Preferences](https://arxiv.org/pdf/1706.03741)

Key concepts:
  - learning user preferences
  - reward predictor
  - challenges of RLHF

---

[Aligning language models to follow instructions](https://openai.com/research/instruction-following)

Key concepts:
  - Alignment research
  - Use RLHF to provide demonstrations of desired model behavior
  - InstructGPT models give more truthful, safer outputs
  - Supervised fine tuning
  - Reward model
 
2. Work on `rlhf_lab.ipynb`