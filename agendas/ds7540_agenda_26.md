## DS 7540 Machine Learning IV - Reinforcement Learning: Agenda 26
  
---

### Upcoming Deliverables

- RLHF Quiz: Due Wednesday, Apr 25, 2025 by 11:59 PM 
- Journals 1-11. Due Monday, Apr 25, 2025, 11:59 PM

---

### Content

1. Review [blog](https://openai.com/research/learning-from-human-preferences): Learning from Human Preferences

Key concepts:
  - learning user preferences
  - reward predictor
  - challenges of RLHF

2. Review [paper](https://arxiv.org/pdf/1706.03741): Deep Reinforcement Learning from Human Preferences

---

3. (Time Permitting) Review [blog](https://openai.com/research/instruction-following): Aligning language models to follow instructions

Key concepts:
  - Alignment research
  - Use RLHF to provide demonstrations of desired model behavior
  - InstructGPT models give more truthful, safer outputs
  - Supervised fine tuning
  - Reward model
 
